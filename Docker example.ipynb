{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Serving with Docker\n",
    "\n",
    "* [Dataset](https://www.kaggle.com/snap/amazon-fine-food-reviews/data)\n",
    "* Using Google's [model](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1) from TensorFlow hub - token based text embedding trained on English Google News 200B corpus. [paper](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "* Exporting model as Protobuf\n",
    "* Deploying with Docker gRPC and REST APIs. [tensorflow serving](https://hub.docker.com/r/tensorflow/serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../github/python-data-science/data/docker/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284227, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184502</td>\n",
       "      <td>B001BCVY4W</td>\n",
       "      <td>A1JMR1N9NBYJ1X</td>\n",
       "      <td>Mad Ethyl Flint</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1228176000</td>\n",
       "      <td>Doesn't look like catfood!</td>\n",
       "      <td>When you first open the can, it looks like som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182779</td>\n",
       "      <td>B0052LZ6XI</td>\n",
       "      <td>A2CVFBDRXYFZG9</td>\n",
       "      <td>vanostran</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1335657600</td>\n",
       "      <td>Solid Mayo</td>\n",
       "      <td>This is a solid mayo. Will not disappoint. At ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0  184502  B001BCVY4W  A1JMR1N9NBYJ1X  Mad Ethyl Flint                     0   \n",
       "1  182779  B0052LZ6XI  A2CVFBDRXYFZG9        vanostran                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                     Summary  \\\n",
       "0                       0      4  1228176000  Doesn't look like catfood!   \n",
       "1                       0      5  1335657600                  Solid Mayo   \n",
       "\n",
       "                                                Text  \n",
       "0  When you first open the can, it looks like som...  \n",
       "1  This is a solid mayo. Will not disappoint. At ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284227 entries, 0 to 284226\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      284227 non-null  int64 \n",
      " 1   ProductId               284227 non-null  object\n",
      " 2   UserId                  284227 non-null  object\n",
      " 3   ProfileName             284216 non-null  object\n",
      " 4   HelpfulnessNumerator    284227 non-null  int64 \n",
      " 5   HelpfulnessDenominator  284227 non-null  int64 \n",
      " 6   Score                   284227 non-null  int64 \n",
      " 7   Time                    284227 non-null  int64 \n",
      " 8   Summary                 284213 non-null  object\n",
      " 9   Text                    284227 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    181679\n",
       "4     40075\n",
       "1     26369\n",
       "3     21305\n",
       "2     14799\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, num_samples):\n",
    "    df = pd.read_csv(file_path, usecols=[6,9], nrows=num_samples)\n",
    "    df.columns = ['rating','title']\n",
    "    text = df['title'].tolist()\n",
    "    text = [str(t).encode(encoding='ascii', errors='replace') for t in text]\n",
    "    text = np.array(text, dtype=object)\n",
    "    \n",
    "    labels = df['rating'].tolist()\n",
    "    labels = [1 if i>=4 else 0 if i==3 else -1 for i in labels]\n",
    "    labels = np.array(pd.get_dummies(labels), dtype=int)\n",
    "    return text, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '../../github/python-data-science/data/docker/train.csv'\n",
    "test_data  = '../../github/python-data-science/data/docker/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_text, temp_lab = load_data(train_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_lab[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google's model from TensorFlow hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\n",
    "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\n",
    "\n",
    "# Model 1\n",
    "# def get_model():\n",
    "#     hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\", output_shape=[128],\n",
    "#                                input_shape=[], dtype=tf.string, name='input', trainable=False)\n",
    "#     model = tf.keras.Sequential()\n",
    "#     model.add(hub_layer)\n",
    "#     model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "#     model.add(tf.keras.layers.Dense(3, activation='softmax', name='output'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "#     model.summary()\n",
    "#     return model\n",
    "\n",
    "# Model 2\n",
    "def get_model():\n",
    "    hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", output_shape=[128],\n",
    "                               input_shape=[], dtype=tf.string, name='input', trainable=False)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(3, activation='softmax', name='output'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (KerasLayer)          (None, 128)               124642688 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,651,139\n",
      "Trainable params: 8,451\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2972da35670>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([ 0.05650096,  0.2567145 ,  0.24404189,  0.14395264, -0.05569138,\n",
       "       -0.10513686,  0.09544804,  0.3080969 , -0.218672  , -0.03048538,\n",
       "       -0.19036277,  0.01005417,  0.11541115, -0.14860378,  0.03914931,\n",
       "       -0.2561884 , -0.15442336,  0.12836292,  0.0469152 , -0.1500514 ,\n",
       "       -0.13068351, -0.01958708,  0.09192695,  0.1208052 , -0.12291992,\n",
       "       -0.04548305, -0.3679261 ,  0.05125156,  0.09797382, -0.10217863,\n",
       "       -0.1965521 ,  0.15523128, -0.05881735, -0.16426983,  0.06646369,\n",
       "        0.05789638,  0.15421619, -0.24014738,  0.11075415, -0.10756174,\n",
       "       -0.01679449, -0.01877424,  0.18602087,  0.2623015 , -0.3829217 ,\n",
       "       -0.34895867, -0.0868978 ,  0.02295742,  0.03787762, -0.02646483],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = hub.load('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1')\n",
    "embeddings = embed(['this is a test', 'look at the embeddings'])\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(EPOCHS=5, BATCH_SIZE=32, TRAIN_FILE=train_data, VAL_FILE=test_data):\n",
    "    print('Loading train/test data...')\n",
    "    x_train, y_train = load_data(TRAIN_FILE, 100000)\n",
    "    x_val, y_val     = load_data(VAL_FILE,  10000)\n",
    "    \n",
    "    print('Training model...')\n",
    "    model = get_model()\n",
    "    WORKING_DIR = os.getcwd()    \n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "             validation_data=(x_val, y_val),\n",
    "             callbacks=[tf.keras.callbacks.ModelCheckpoint(os.path.join(WORKING_DIR, 'model_checkpoint'), \n",
    "                                                          monitor='val_loss', verbose=0,\n",
    "                                                          save_best_model=True,\n",
    "                                                          save_weights_only=False,\n",
    "                                                          model='auto')])\n",
    "    return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model, base_path='model_review/'):\n",
    "    path = os.path.join(base_path, str(int(time.time())))\n",
    "    tf.saved_model.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/test data...\n",
      "Training model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (KerasLayer)          (None, 128)               124642688 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,651,139\n",
      "Trainable params: 8,451\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "3105/3125 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.8005INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 11s 3ms/step - loss: 0.5329 - accuracy: 0.8004 - val_loss: 0.5142 - val_accuracy: 0.8053\n",
      "Epoch 2/5\n",
      "3115/3125 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.8101INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 10s 3ms/step - loss: 0.5028 - accuracy: 0.8102 - val_loss: 0.5165 - val_accuracy: 0.8071\n",
      "Epoch 3/5\n",
      "3107/3125 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8127INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 10s 3ms/step - loss: 0.4956 - accuracy: 0.8125 - val_loss: 0.4978 - val_accuracy: 0.8128\n",
      "Epoch 4/5\n",
      "3105/3125 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.8146INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 10s 3ms/step - loss: 0.4892 - accuracy: 0.8148 - val_loss: 0.4981 - val_accuracy: 0.8107\n",
      "Epoch 5/5\n",
      "3115/3125 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.8167INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\uditg\\Documents\\Python Scripts\\Lessons\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 10s 3ms/step - loss: 0.4835 - accuracy: 0.8167 - val_loss: 0.4924 - val_accuracy: 0.8138\n",
      "INFO:tensorflow:Assets written to: model_review/1648794896\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_review/1648794896\\assets\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = train_model()\n",
    "    export_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9178998 , 0.01348544, 0.06861478]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['Bad book, waste of time, do not buy'])\n",
    "# model 1 - array([[0.6144746 , 0.05491435, 0.33061108]], dtype=float32)\n",
    "# model 2 - array([[0.9178998 , 0.01348544, 0.06861478]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01482655, 0.00417724, 0.98099625]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['Awesome product'])\n",
    "# model 1 - array([[0.01603218, 0.01620099, 0.9677669 ]], dtype=float32)\n",
    "# model 2 - array([[0.01482655, 0.00417724, 0.98099625]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker pull tensorflow/serving\n",
    "\n",
    "# docker run -p 8500:8500 -p 8501:8501 --mount type=bind,source=\"C:/users/uditg/documents/python scripts/lessons/\"model_review\\,target=/models/model_review -e MODEL_NAME=model_review -t tensorflow/serving\n",
    "\n",
    "# Model manager behind tensorflow/serving automatically unloads old model and uploads new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoints - REST or gRPC\n",
    " TensorFlow Serving supports\n",
    "- Remote Procedure Protocal (gRPC) - default port 8500\n",
    "- Representational State Transfer (REST) - default port 8501\n",
    "- Consistent API structures. Server supports both standards simultaneously\n",
    "\n",
    "### gRPC vs. REST\n",
    "- Rest is easy to implement and debug\n",
    "- RPC is more network efficient, smaller payloads and can provide much faster inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using REST url\n",
    "\n",
    "- Standard HTTP POST requests\n",
    "- Response is a JSON body with the prediction\n",
    "- Request from the default or specific model  \n",
    "Default URI scheme: `http://{HOST}:{PORT}/v1/models/{MODEL_NAME}`  \n",
    "Specific model versions: `http://{HOST}:{PORT}/v1/models/{MODEL_NAME}[/versions/{MODEL_VERSION}]:predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rest_url(model_name, host='127.0.0.1', port='8501', verb='predict', version=None):\n",
    "    url = \"http://{host}:{port}/v1/models/{model_name}\".format(host=host, port=port, model_name=model_name)\n",
    "    if version:\n",
    "        url += 'versions/{version}'.format(version=version)\n",
    "    url += ':{verb}'.format(verb=verb)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction(model_input, model_name='model_review', signature_name='serving_default'):\n",
    "    url = get_rest_url(model_name)\n",
    "    \n",
    "    #In the row format, inputs are keyed to instances key in the JSON request.\n",
    "    #When there is only one named input, specify the value of instances key to be the value of the input:\n",
    "    data = {\"instances\": [model_input]}\n",
    "    \n",
    "    rv = requests.post(url, data=json.dumps(data))\n",
    "    if rv.status_code != requests.codes.ok:\n",
    "        rv.raise_for_status()\n",
    "    \n",
    "    return rv.json()['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate REST url ...\n",
      "http://127.0.0.1:8501/v1/models/model_review:predict\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      "'Bad book, waste of time, do not buy'\n",
      "The model predicted ...\n",
      "[[0.876614928, 0.0399460234, 0.0834390745]]\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      "Awesome product\n",
      "The model predicted ...\n",
      "[[0.0148265501, 0.00417723553, 0.980996251]]\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      "Bad book, waste of time, do not buy\n",
      "The model predicted ...\n",
      "[[0.917899787, 0.013485441, 0.0686147809]]\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      ":q\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"\\nGenerate REST url ...\")\n",
    "    url = get_rest_url(model_name='model_review')\n",
    "    print(url)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nEnter a product review [:q for Quit]\")\n",
    "        if sys.version_info[0] <= 3:                     # checks python version\n",
    "            sentence = input()\n",
    "        if sentence == ':q':\n",
    "            break\n",
    "        model_input = sentence\n",
    "        model_prediction = get_model_prediction(model_input)\n",
    "        print(\"The model predicted ...\")\n",
    "        print(model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gRPC client\n",
    "\n",
    "More sophisticated client-server connections\n",
    "- Prediction data has to be converted to the Protobuf format\n",
    "- Request types have designated types, e.g. float, int, bytes\n",
    "- Payloads need to be converted to base64\n",
    "- Connect to the server via gRPC stubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-serving-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import grpc\n",
    "from grpc.beta import implementations\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2, get_model_metadata_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create RPC connection ...\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      "Bad book, waste of time, do not buy\n",
      "The model predicted ...\n",
      "[0.9178997874259949, 0.013485440984368324, 0.06861478090286255]\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      "Awesome product\n",
      "The model predicted ...\n",
      "[0.014826550148427486, 0.004177235532552004, 0.9809962511062622]\n",
      "\n",
      "Enter a product review [:q for Quit]\n",
      ":q\n"
     ]
    }
   ],
   "source": [
    "def get_stub(host='127.0.0.1', port='8500'):\n",
    "    channel = grpc.insecure_channel('127.0.0.1:8500') \n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    return stub\n",
    "\n",
    "def get_model_prediction(model_input, stub, model_name='model_review', signature_name='serving_default'):\n",
    "    \"\"\" no error handling at all, just poc\"\"\"\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = model_name\n",
    "    request.model_spec.signature_name = signature_name\n",
    "    request.inputs['input_input'].CopyFrom(tf.make_tensor_proto(model_input))\n",
    "    response = stub.Predict.future(request, 5.0)  # 5 seconds\n",
    "    return response.result().outputs[\"output\"].float_val\n",
    "\n",
    "def get_model_version(model_name, stub):\n",
    "    request = get_model_metadata_pb2.GetModelMetadataRequest()\n",
    "    request.model_spec.name = 'model_review'\n",
    "    request.metadata_field.append(\"signature_def\")\n",
    "    response = stub.GetModelMetadata(request, 10)\n",
    "    # signature of loaded model is available here: response.metadata['signature_def']\n",
    "    return response.model_spec.version.value\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\nCreate RPC connection ...\")\n",
    "    stub = get_stub()\n",
    "    while True:\n",
    "        print(\"\\nEnter a product review [:q for Quit]\")\n",
    "        if sys.version_info[0] <= 3:\n",
    "            sentence = raw_input() if sys.version_info[0] < 3 else input()\n",
    "        if sentence == ':q':\n",
    "            break\n",
    "        model_input = [sentence]\n",
    "        model_prediction = get_model_prediction(model_input, stub)\n",
    "        print(\"The model predicted ...\")\n",
    "        print(model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
